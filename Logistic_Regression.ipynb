{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# Mount to Google Drive in order to upload data files\n",
        "drive.mount('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff-fEpNlXKSG",
        "outputId": "100f0e29-46f6-4714-f8d6-013be3002ef5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3icXNTGYdR1"
      },
      "outputs": [],
      "source": [
        "# 3 years\n",
        "\n",
        "# Import 3 years of combined data\n",
        "data3 = pd.read_csv('path_to_combined_3year_data.csv')\n",
        "\n",
        "# Convert 'date' column to datetime type\n",
        "data3['date'] = pd.to_datetime(data3['date'])\n",
        "\n",
        "# Define threshold for classifying \"high volatility\" (top 30% of Target per ticker)\n",
        "data3['high_volatility'] = data3.groupby('ticker')['Target'].transform(lambda x: np.where(x > x.quantile(0.7), 1, 0))\n",
        "\n",
        "# Initialize lists to store results and confusion matrices per ticker\n",
        "results3 = []\n",
        "ticker_confusion_matrices_3 = {}\n",
        "\n",
        "# Loop through each ticker to train and evaluate model\n",
        "for ticker in data3['ticker'].unique():\n",
        "\n",
        "    # Select data for the current ticker and sort by date\n",
        "    ticker_df_3 = data3[data3['ticker'] == ticker].sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    # Define feature columns\n",
        "    features_3 = ['RealizedVol_3d', 'comment_volume', 'average_sentiment']\n",
        "\n",
        "    # Split data into train/test based on 80% quantile date\n",
        "    split_date_3 = ticker_df_3['date'].quantile(0.8)\n",
        "    train_3 = ticker_df_3[ticker_df_3['date'] <= split_date_3]\n",
        "    test_3 = ticker_df_3[ticker_df_3['date'] > split_date_3]\n",
        "\n",
        "    # Define features and target\n",
        "    X_train_3 = train_3[features_3]\n",
        "    y_train_3 = train_3['high_volatility']\n",
        "    X_test_3 = test_3[features_3]\n",
        "    y_test_3 = test_3['high_volatility']\n",
        "\n",
        "    # Standardize features to have mean=0 and variance=1\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled_3 = scaler.fit_transform(X_train_3)\n",
        "    X_test_scaled_3 = scaler.transform(X_test_3)\n",
        "\n",
        "    # Initialize and fit logistic regression model\n",
        "    model3 = LogisticRegression(random_state=42)\n",
        "    model3.fit(X_train_scaled_3, y_train_3)\n",
        "\n",
        "    # Make predictions and predicted probabilities on the test set\n",
        "    y_pred_3 = model3.predict(X_test_scaled_3)\n",
        "    y_prob_3 = model3.predict_proba(X_test_scaled_3)[:, 1]\n",
        "\n",
        "    # Store results for this ticker in a DataFrame\n",
        "    test_results_3 = pd.DataFrame({\n",
        "    'date': test_3['date'].values,\n",
        "    'ticker': ticker,\n",
        "    'target': test_3['Target'].values,\n",
        "    'high_volatility_actual': y_test_3.values,\n",
        "    'high_volatility_pred': y_pred_3,\n",
        "    'probability': y_prob_3\n",
        "    })\n",
        "\n",
        "    # Append ticker results to the list\n",
        "    results3.append(test_results_3)\n",
        "\n",
        "# Concatenate results from all tickers\n",
        "results_df_3 = pd.concat(results3).reset_index(drop=True)\n",
        "\n",
        "# Count total misclassified samples\n",
        "num_misclassified_3 = (results_df_3['high_volatility_actual'] != results_df_3['high_volatility_pred']).sum()\n",
        "\n",
        "# Generate high-confidence trading signals using probability threshold\n",
        "confidence_thresh = 0.9\n",
        "results_df_3[\"signal\"] = (results_df_3[\"probability\"] > confidence_thresh).astype(int)\n",
        "n_signals = results_df_3[\"signal\"].sum()\n",
        "print(f\"Trade Signals Triggered: {n_signals} out of {len(results_df_3)} samples\")\n",
        "\n",
        "# Calculate precision of high-confidence signals\n",
        "precision = precision_score(results_df_3[\"high_volatility_actual\"], results_df_3[\"signal\"])\n",
        "print(f\"Precision of High-Confidence Strategy: {precision:.3f}\")\n",
        "print()\n",
        "\n",
        "# Identify top 5 high-confidence predictions\n",
        "top_signals = pd.DataFrame({\n",
        "    'probability': y_prob_3,\n",
        "    'true_label': y_test_3.values,\n",
        "    'date': test_3['date'].values\n",
        "})\n",
        "print(f\"\\nTop 5 high-confidence predictions for {ticker}:\")\n",
        "print(top_signals.sort_values(\"probability\", ascending=False).head(5))\n",
        "print()\n",
        "\n",
        "# Compute confusion matrix per ticker\n",
        "for ticker in results_df_3['ticker'].unique():\n",
        "    subset_3 = results_df_3[results_df_3['ticker'] == ticker]\n",
        "    cm3 = confusion_matrix(subset_3['high_volatility_actual'], subset_3['high_volatility_pred'], labels=[0, 1])\n",
        "    ticker_confusion_matrices_3[ticker] = cm3\n",
        "\n",
        "# Print confusion matrices for each ticker\n",
        "for ticker, cm3 in ticker_confusion_matrices_3.items():\n",
        "    print(f\"Confusion Matrix for {ticker}:\")\n",
        "    print(cm3)\n",
        "    print()\n",
        "\n",
        "# Compute overall ROC AUC score across all tickers\n",
        "overall_auc = roc_auc_score(results_df_3['high_volatility_actual'], results_df_3['probability'])\n",
        "print(f\"Overall ROC AUC Score: {overall_auc:.3f}\")\n",
        "print()\n",
        "\n",
        "# Print overall model performance\n",
        "print(\"Overall Model Performance:\")\n",
        "print(confusion_matrix(results_df_3['high_volatility_actual'], results_df_3['high_volatility_pred']))\n",
        "print()\n",
        "print(classification_report(results_df_3['high_volatility_actual'], results_df_3['high_volatility_pred']))\n",
        "print()\n",
        "\n",
        "# Print first 10 rows of results\n",
        "print(results_df_3.head(10))\n",
        "print()\n",
        "\n",
        "# Print total number of misclassified samples\n",
        "print(num_misclassified_3)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb170b3-3275-446b-a669-5b3f9f40f684",
        "collapsed": true,
        "id": "gHpuj6J8-4yU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for AAPL:\n",
            "[[49  0]\n",
            " [16  0]]\n",
            "\n",
            "Confusion Matrix for AMZN:\n",
            "[[43  0]\n",
            " [19  0]]\n",
            "\n",
            "Confusion Matrix for BRK-B:\n",
            "[[44  0]\n",
            " [16  0]]\n",
            "\n",
            "Confusion Matrix for COST:\n",
            "[[55  0]\n",
            " [16  0]]\n",
            "\n",
            "Confusion Matrix for GOOG:\n",
            "[[48  0]\n",
            " [17  0]]\n",
            "\n",
            "Confusion Matrix for GOOGL:\n",
            "[[51  1]\n",
            " [17  0]]\n",
            "\n",
            "Confusion Matrix for HD:\n",
            "[[45  3]\n",
            " [15  0]]\n",
            "\n",
            "Confusion Matrix for KO:\n",
            "[[53  0]\n",
            " [14  0]]\n",
            "\n",
            "Confusion Matrix for META:\n",
            "[[60  0]\n",
            " [ 8  0]]\n",
            "\n",
            "Confusion Matrix for MSFT:\n",
            "[[50  1]\n",
            " [11  1]]\n",
            "\n",
            "Confusion Matrix for NVDA:\n",
            "[[55  0]\n",
            " [ 8  0]]\n",
            "\n",
            "Confusion Matrix for PG:\n",
            "[[53  0]\n",
            " [14  0]]\n",
            "\n",
            "Confusion Matrix for PLTR:\n",
            "[[46  0]\n",
            " [13  1]]\n",
            "\n",
            "Confusion Matrix for PM:\n",
            "[[53  0]\n",
            " [15  0]]\n",
            "\n",
            "Confusion Matrix for TSLA:\n",
            "[[57  0]\n",
            " [12  0]]\n",
            "\n",
            "Overall Model Performance:\n",
            "[[762   5]\n",
            " [211   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.99      0.88       767\n",
            "           1       0.29      0.01      0.02       213\n",
            "\n",
            "    accuracy                           0.78       980\n",
            "   macro avg       0.53      0.50      0.45       980\n",
            "weighted avg       0.68      0.78      0.69       980\n",
            "\n",
            "        date ticker    target  high_volatility_actual  high_volatility_pred\n",
            "0 2024-08-14   AAPL  0.007194                       0                     0\n",
            "1 2024-08-15   AAPL  0.007194                       0                     0\n",
            "2 2024-08-16   AAPL  0.006001                       0                     0\n",
            "3 2024-08-27   AAPL  0.010662                       0                     0\n",
            "4 2024-08-28   AAPL  0.012988                       0                     0\n",
            "5 2024-09-04   AAPL  0.021396                       1                     0\n",
            "6 2024-09-04   AAPL  0.009404                       1                     0\n",
            "7 2024-09-09   AAPL  0.007366                       0                     0\n",
            "8 2024-09-16   AAPL  0.009890                       0                     0\n",
            "9 2024-09-17   AAPL  0.009890                       0                     0\n",
            "216\n"
          ]
        }
      ],
      "source": [
        "# 1 year\n",
        "\n",
        "# Import 1 year of combined data\n",
        "data1 = pd.read_csv('path_to_combined_1year_data.csv')\n",
        "\n",
        "# Convert 'date' column to datetime type\n",
        "data1['date'] = pd.to_datetime(data3['date'])\n",
        "\n",
        "# Define threshold for classifying \"high volatility\" (top 30% of Target per ticker)\n",
        "data1['high_volatility'] = data3.groupby('ticker')['Target'].transform(lambda x: np.where(x > x.quantile(0.7), 1, 0))\n",
        "\n",
        "# Initialize lists to store results and confusion matrices per ticker\n",
        "results1 = []\n",
        "ticker_confusion_matrices_1 = {}\n",
        "\n",
        "# Loop through each ticker to train and evaluate model\n",
        "for ticker in data1['ticker'].unique():\n",
        "\n",
        "    # Select data for the current ticker and sort by date\n",
        "    ticker_df_1 = data1[data1['ticker'] == ticker].sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    # Define features for the 1-year model\n",
        "    features_1 = ['RealizedVol_3d', 'reddit_sentiment_lag1', 'reddit_volume_lag1', 'news_sentiment_lag1', 'news_volume_lag1']\n",
        "\n",
        "    # Split data into train/test based on 80% quantile date\n",
        "    split_date_1 = ticker_df_1['date'].quantile(0.8)\n",
        "    train_1 = ticker_df_1[ticker_df_1['date'] <= split_date_1]\n",
        "    test_1 = ticker_df_1[ticker_df_1['date'] > split_date_1]\n",
        "\n",
        "    # Define features and target\n",
        "    X_train_1 = train_1[features_1]\n",
        "    y_train_1 = train_1['high_volatility']\n",
        "    X_test_1 = test_1[features_1]\n",
        "    y_test_1 = test_1['high_volatility']\n",
        "\n",
        "    # Standardize features to have mean=0 and variance=1\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled_1 = scaler.fit_transform(X_train_1)\n",
        "    X_test_scaled_1 = scaler.transform(X_test_1)\n",
        "\n",
        "    # Initialize and fit logistic regression model\n",
        "    model1 = LogisticRegression(random_state=42)\n",
        "    model1.fit(X_train_scaled_1, y_train_1)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_1 = model1.predict(X_test_scaled_1)\n",
        "\n",
        "    # Store results for this ticker in a DataFrame\n",
        "    test_results_1 = pd.DataFrame({\n",
        "    'date': test_1['date'].values,\n",
        "    'ticker': ticker,\n",
        "    'target': test_1['Target'].values,\n",
        "    'high_volatility_actual': y_test_1.values,\n",
        "    'high_volatility_pred': y_pred_1,\n",
        "    })\n",
        "\n",
        "    # Append ticker results to the list\n",
        "    results1.append(test_results_1)\n",
        "\n",
        "\n",
        "# Concatenate results from all tickers\n",
        "results_df_1 = pd.concat(results1).reset_index(drop=True)\n",
        "\n",
        "# Count total misclassified samples\n",
        "num_misclassified_1 = (results_df_1['high_volatility_actual'] != results_df_1['high_volatility_pred']).sum()\n",
        "\n",
        "# Compute confusion matrix per ticker\n",
        "for ticker in results_df_1['ticker'].unique():\n",
        "    subset = results_df_1[results_df_1['ticker'] == ticker]\n",
        "    cm1 = confusion_matrix(subset['high_volatility_actual'], subset['high_volatility_pred'], labels=[0, 1])\n",
        "    ticker_confusion_matrices_1[ticker] = cm1\n",
        "\n",
        "# Print confusion matrices for each ticker\n",
        "for ticker, cm1 in ticker_confusion_matrices_1.items():\n",
        "    print(f\"Confusion Matrix for {ticker}:\")\n",
        "    print(cm1)\n",
        "    print()  # Blank line for readability\n",
        "\n",
        "# Print overall model performance\n",
        "print(\"Overall Model Performance:\")\n",
        "print(confusion_matrix(results_df_1['high_volatility_actual'], results_df_1['high_volatility_pred']))\n",
        "print(classification_report(results_df_1['high_volatility_actual'], results_df_1['high_volatility_pred']))\n",
        "\n",
        "# Print first 10 rows of results\n",
        "print(results_df_1.head(10))\n",
        "\n",
        "# Print total number of misclassified samples\n",
        "print(num_misclassified_1)"
      ]
    }
  ]
}