{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"UpRte2ziwSVu"},"outputs":[],"source":["import pandas as pd\n","df_news = pd.read_csv(\"News1year.csv\", parse_dates=[\"date\"])\n","\n","# Standardize tickers (for BRK-B)\n","df_news[\"ticker\"] = df_news[\"ticker\"].str.upper().str.replace('.', '-', regex=False)\n","\n","# lagged features\n","df_news = df_news.sort_values([\"ticker\", \"date\"])\n","df_news[\"news_sentiment_lag1\"] = df_news.groupby(\"ticker\")[\"average_sentiment\"].shift(1)\n","df_news[\"news_volume_lag1\"] = df_news.groupby(\"ticker\")[\"comment_volume\"].shift(1)\n","print(df_news.shape)\n","\n","df_news_lag = df_news[[\"date\", \"ticker\", \"news_sentiment_lag1\", \"news_volume_lag1\"]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f9u4DM6wSVx"},"outputs":[],"source":["print(df_news_lag.shape)\n","print(df_news_lag.head())\n","print(f\"NaNs?:\\n{df_news_lag[['news_sentiment_lag1', 'news_volume_lag1']].isna().sum()}\")\n","\n","df_yr = pd.read_csv('yahooredditcombined.csv', parse_dates = ['date'])\n","\n","combined = df_yr.merge(\n","    df_news_lag,\n","    on=[\"date\", \"ticker\"],\n","    how=\"left\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKnNPZvFwSVy"},"outputs":[],"source":["print(combined.shape)\n","print(combined.head(100))\n","print(f\"NaNs?:\\n{combined[['news_sentiment_lag1', 'news_volume_lag1']].isna().sum()}\")\n","\n","missing_news = combined[combined[\"news_sentiment_lag1\"].isna()]\n","print(missing_news[[\"date\", \"ticker\"]].head(10))\n","\n","missing_per_ticker = (\n","    combined[combined[\"news_sentiment_lag1\"].isna()]\n","    .groupby(\"ticker\")\n","    .size()\n","    .sort_values(ascending=False)\n",")\n","\n","print(\"Tickers with most missing news sentiment:\")\n","print(missing_per_ticker.head(10))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9smGl9ETwSVy"},"outputs":[],"source":["combined[\"news_missing\"] = combined[\"news_sentiment_lag1\"].isna().astype(int)\n","\n","# === Fill missing values with 0.0 for models that can't handle NaNs (e.g. logistic regression) ===\n","combined[\"news_sentiment_lag1\"] = combined[\"news_sentiment_lag1\"].fillna(0.0)\n","combined[\"news_volume_lag1\"] = combined[\"news_volume_lag1\"].fillna(0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ow_NFIhwSVz"},"outputs":[],"source":["print(\"Any NaNs left?\", combined.isna().sum().sum())\n","print(combined.isna().sum())\n","print(combined.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wW5SpBHIwSVz"},"outputs":[],"source":["combined.to_csv('FINAL_1YEAR_DATA.csv',index=False)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}