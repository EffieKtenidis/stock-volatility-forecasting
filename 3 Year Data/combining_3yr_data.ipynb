{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This code takes a csv file with sentiment file already replaced missing dates with 0 (for sentiment), shifts the news data so that it is aligned with the day before, and then combines with the financial data"],"metadata":{"id":"jAtZNT_oOavz"}},{"cell_type":"code","source":["!pip install pandas_market_calendars"],"metadata":{"id":"pqFCNVDTwL2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2sAjbYBuPiL"},"outputs":[],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"code","source":["import pandas as pd\n","import pandas_market_calendars as mcal\n","\n","# Load your data\n","df = pd.read_csv(\"year3news.csv\")\n","df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.normalize()  #normalize to remove time component\n","df = df.sort_values(by=[\"ticker\", \"date\"])\n","print(df.head(20))"],"metadata":{"id":"e66oFIeOv5pA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#sort by ticker and date to ensure proper shifting\n","df = df.sort_values(by=[\"ticker\", \"date\"])\n","\n","#shift the columns up by one day within each ticker group\n","df[\"comment_volume\"] = df.groupby(\"ticker\")[\"comment_volume\"].shift(1)\n","df[\"average_sentiment\"] = df.groupby(\"ticker\")[\"average_sentiment\"].shift(1)\n","\n","df = df.dropna(subset=[\"comment_volume\", \"average_sentiment\"])\n","\n","print(df.head(20))\n","\n","print(df[\"date\"].min(), \"to\", df[\"date\"].max())"],"metadata":{"id":"Y4bkIS3-w3eA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"metadata":{"id":"X4g4534wN3yZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","#load the datasets\n","finance_data = pd.read_csv(\"3year_finance_data.csv\")\n","\n","#convert 'date' columns to datetime and normalize\n","df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.normalize()\n","finance_data[\"date\"] = pd.to_datetime(finance_data[\"date\"]).dt.normalize()\n","\n","# merge on 'date' and 'ticker'\n","combined_df = pd.merge(finance_data, df, on=[\"date\", \"ticker\"], how=\"inner\")\n","\n","#drop unnecessary columns\n","if \"Unnamed: 0\" in combined_df.columns:\n","    combined_df = combined_df.drop(columns=[\"Unnamed: 0\"])\n","\n","#sort by ticker and date\n","combined_df = combined_df.sort_values(by=[\"ticker\", \"date\"]).reset_index(drop=True)\n","\n","#preview the first few rows\n","print(combined_df.head(20))\n","\n","# uncomment below to save to new CSV\n","#combined_df.to_csv(\"Combined_3year_data.csv\", index=False)\n","\n","#from google.colab import files\n","#files.download(\"Combined_3year_data.csv\")\n"],"metadata":{"id":"xA27UbQrNGvT"},"execution_count":null,"outputs":[]}]}